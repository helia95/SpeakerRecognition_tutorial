{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from python_speech_features import fbank\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_frames(m,Scale=True):\n",
    "    if Scale:\n",
    "        return (m - np.mean(m, axis=0)) / (np.std(m, axis=0) + 2e-12)\n",
    "    else:\n",
    "        return (m - np.mean(m, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute features and store it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_info_file = '/cas/DeepLearn/elperu/tmp/speech_datasets/LibriSpeech/dataset_info.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset_info_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spk_id</th>\n",
       "      <th>ch_id</th>\n",
       "      <th>utter_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>374</td>\n",
       "      <td>180299</td>\n",
       "      <td>/cas/DeepLearn/elperu/tmp/speech_datasets/Libr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>374</td>\n",
       "      <td>180299</td>\n",
       "      <td>/cas/DeepLearn/elperu/tmp/speech_datasets/Libr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>374</td>\n",
       "      <td>180299</td>\n",
       "      <td>/cas/DeepLearn/elperu/tmp/speech_datasets/Libr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>374</td>\n",
       "      <td>180299</td>\n",
       "      <td>/cas/DeepLearn/elperu/tmp/speech_datasets/Libr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>374</td>\n",
       "      <td>180299</td>\n",
       "      <td>/cas/DeepLearn/elperu/tmp/speech_datasets/Libr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>4640</td>\n",
       "      <td>19187</td>\n",
       "      <td>/cas/DeepLearn/elperu/tmp/speech_datasets/Libr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>4640</td>\n",
       "      <td>19187</td>\n",
       "      <td>/cas/DeepLearn/elperu/tmp/speech_datasets/Libr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>4640</td>\n",
       "      <td>19187</td>\n",
       "      <td>/cas/DeepLearn/elperu/tmp/speech_datasets/Libr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>4640</td>\n",
       "      <td>19187</td>\n",
       "      <td>/cas/DeepLearn/elperu/tmp/speech_datasets/Libr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>4640</td>\n",
       "      <td>19187</td>\n",
       "      <td>/cas/DeepLearn/elperu/tmp/speech_datasets/Libr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      spk_id   ch_id                                         utter_path\n",
       "0        374  180299  /cas/DeepLearn/elperu/tmp/speech_datasets/Libr...\n",
       "1        374  180299  /cas/DeepLearn/elperu/tmp/speech_datasets/Libr...\n",
       "2        374  180299  /cas/DeepLearn/elperu/tmp/speech_datasets/Libr...\n",
       "3        374  180299  /cas/DeepLearn/elperu/tmp/speech_datasets/Libr...\n",
       "4        374  180299  /cas/DeepLearn/elperu/tmp/speech_datasets/Libr...\n",
       "...      ...     ...                                                ...\n",
       "9995    4640   19187  /cas/DeepLearn/elperu/tmp/speech_datasets/Libr...\n",
       "9996    4640   19187  /cas/DeepLearn/elperu/tmp/speech_datasets/Libr...\n",
       "9997    4640   19187  /cas/DeepLearn/elperu/tmp/speech_datasets/Libr...\n",
       "9998    4640   19187  /cas/DeepLearn/elperu/tmp/speech_datasets/Libr...\n",
       "9999    4640   19187  /cas/DeepLearn/elperu/tmp/speech_datasets/Libr...\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N users: 250\n",
      "Current users: [ 374 7800 2514 3240 1088 5456 5750 1246 8238 1263 7505  587  226 1743\n",
      " 4214 5789 7635 5390  307 7447 4362 6529  233 3242 1624 4297 6181 6367\n",
      " 3723 7113 6563  403 5778 3112 7367 7078   32 5322 3214 6818  481 5104\n",
      " 6385 5192 8226 3830 2989 8324  163  150 6476 1069 3983 1183 4788  426\n",
      "  311 2196  103  446 1502 8975 8770 1992 5678 8014 2182 7178  201 1034\n",
      " 5703 1363  250 6836 3168 1553 5163   89 1334   19 5393 4481 4160 8312\n",
      " 6415   87 7067 5688 2843  909   40  322 8797 2764 6848 3947 4014 6531\n",
      " 3664 3259 4441 5049 4018 4088 4853 7226 4859   78 3440  460 2893 4680\n",
      "  302 4830 2518 4898 7780 1926 1963 1841 3526  254 1970 6209  458 7148\n",
      "  831 6147  839 8425  200 1723 2416 6019 4813 1455 2391 2910 6000 7302\n",
      " 2817  445 8468 2384 8630 4267   26  118  328 1867 3374 5022 8108 6081\n",
      " 8095 5514 8838 2007 7794 8123 5463 2002  196  248  198 4340 5339 6454\n",
      " 4051 3982 6078 3857 1098 5867 2159   83  730 1235 8629  696  289 1116\n",
      " 5808 8063 8465 6272 6064  412 3607 1594 7278  625 2836 7859 3807 1355\n",
      "  332 8580  911 6880 8051 8088 3436  887 3879   39 3235  211 5652 2136\n",
      " 4406   27 1737 7059  125 3486 2911 7190 6437 2092 7517 6925 8747 7402\n",
      " 8609 2691 2952 1040 1081 2289  298 4397 7264 1578   60  229 3699 8419\n",
      " 4137  405 2436 1898 7511 4195  669 5561 1447  441 8098 4640]\n"
     ]
    }
   ],
   "source": [
    "users = df.spk_id.unique()\n",
    "print(f'N users: {len(users)}\\nCurrent users: {users}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dir tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = '/cas/DeepLearn/elperu/tmp/speech_datasets/LibriSpeech/train_features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(out_path, ignore_errors=True)\n",
    "\n",
    "for user in users:\n",
    "    os.makedirs(os.path.join(out_path, str(user)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 16000\n",
    "\n",
    "tot_rows = []\n",
    "for idx, row in df.iterrows():\n",
    "    \n",
    "    spk_id = row['spk_id']\n",
    "    _path = row['utter_path']\n",
    "    \n",
    "    utter_name = os.path.basename(_path).split('.')[0]\n",
    "    \n",
    "    audio, sr = librosa.load(_path, sr=sample_rate, mono=True)\n",
    "\n",
    "    filter_banks, energies = fbank(audio, samplerate=sample_rate, nfilt=40, winlen=0.025)\n",
    "\n",
    "    filter_banks = 20 * np.log10(np.maximum(filter_banks,1e-5))\n",
    "\n",
    "    feature = normalize_frames(filter_banks, Scale=False)\n",
    "\n",
    "    out = {'label': str(spk_id),\n",
    "           'feat':feature}\n",
    "\n",
    "\n",
    "    pickle_file = os.path.join(out_path, str(spk_id), f'{utter_name}.p')\n",
    "    \n",
    "    tot_rows.append([spk_id, _path, os.path.abspath(pickle_file)])\n",
    "    \n",
    "    with open(pickle_file, 'wb') as f:\n",
    "        pickle.dump(out, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tot_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(tot_rows, columns=['spk_id', 'flac_path', 'feature_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('/cas/DeepLearn/elperu/tmp/speech_datasets/LibriSpeech/train_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('/cas/DeepLearn/elperu/tmp/speech_datasets/LibriSpeech/train_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374, 40\n",
      "7800, 40\n",
      "2514, 40\n",
      "3240, 40\n",
      "1088, 40\n",
      "5456, 40\n",
      "5750, 40\n",
      "1246, 40\n",
      "8238, 40\n",
      "1263, 40\n",
      "7505, 40\n",
      "587, 40\n",
      "226, 40\n",
      "1743, 40\n",
      "4214, 40\n",
      "5789, 40\n",
      "7635, 40\n",
      "5390, 40\n",
      "307, 40\n",
      "7447, 40\n",
      "4362, 40\n",
      "6529, 40\n",
      "233, 40\n",
      "3242, 40\n",
      "1624, 40\n",
      "4297, 40\n",
      "6181, 40\n",
      "6367, 40\n",
      "3723, 40\n",
      "7113, 40\n",
      "6563, 40\n",
      "403, 40\n",
      "5778, 40\n",
      "3112, 40\n",
      "7367, 40\n",
      "7078, 40\n",
      "32, 40\n",
      "5322, 40\n",
      "3214, 40\n",
      "6818, 40\n",
      "481, 40\n",
      "5104, 40\n",
      "6385, 40\n",
      "5192, 40\n",
      "8226, 40\n",
      "3830, 40\n",
      "2989, 40\n",
      "8324, 40\n",
      "163, 40\n",
      "150, 40\n",
      "6476, 40\n",
      "1069, 40\n",
      "3983, 40\n",
      "1183, 40\n",
      "4788, 40\n",
      "426, 40\n",
      "311, 40\n",
      "2196, 40\n",
      "103, 40\n",
      "446, 40\n",
      "1502, 40\n",
      "8975, 40\n",
      "8770, 40\n",
      "1992, 40\n",
      "5678, 40\n",
      "8014, 40\n",
      "2182, 40\n",
      "7178, 40\n",
      "201, 40\n",
      "1034, 40\n",
      "5703, 40\n",
      "1363, 40\n",
      "250, 40\n",
      "6836, 40\n",
      "3168, 40\n",
      "1553, 40\n",
      "5163, 40\n",
      "89, 40\n",
      "1334, 40\n",
      "19, 40\n",
      "5393, 40\n",
      "4481, 40\n",
      "4160, 40\n",
      "8312, 40\n",
      "6415, 40\n",
      "87, 40\n",
      "7067, 40\n",
      "5688, 40\n",
      "2843, 40\n",
      "909, 40\n",
      "40, 40\n",
      "322, 40\n",
      "8797, 40\n",
      "2764, 40\n",
      "6848, 40\n",
      "3947, 40\n",
      "4014, 40\n",
      "6531, 40\n",
      "3664, 40\n",
      "3259, 40\n",
      "4441, 40\n",
      "5049, 40\n",
      "4018, 40\n",
      "4088, 40\n",
      "4853, 40\n",
      "7226, 40\n",
      "4859, 40\n",
      "78, 40\n",
      "3440, 40\n",
      "460, 40\n",
      "2893, 40\n",
      "4680, 40\n",
      "302, 40\n",
      "4830, 40\n",
      "2518, 40\n",
      "4898, 40\n",
      "7780, 40\n",
      "1926, 40\n",
      "1963, 40\n",
      "1841, 40\n",
      "3526, 40\n",
      "254, 40\n",
      "1970, 40\n",
      "6209, 40\n",
      "458, 40\n",
      "7148, 40\n",
      "831, 40\n",
      "6147, 40\n",
      "839, 40\n",
      "8425, 40\n",
      "200, 40\n",
      "1723, 40\n",
      "2416, 40\n",
      "6019, 40\n",
      "4813, 40\n",
      "1455, 40\n",
      "2391, 40\n",
      "2910, 40\n",
      "6000, 40\n",
      "7302, 40\n",
      "2817, 40\n",
      "445, 40\n",
      "8468, 40\n",
      "2384, 40\n",
      "8630, 40\n",
      "4267, 40\n",
      "26, 40\n",
      "118, 40\n",
      "328, 40\n",
      "1867, 40\n",
      "3374, 40\n",
      "5022, 40\n",
      "8108, 40\n",
      "6081, 40\n",
      "8095, 40\n",
      "5514, 40\n",
      "8838, 40\n",
      "2007, 40\n",
      "7794, 40\n",
      "8123, 40\n",
      "5463, 40\n",
      "2002, 40\n",
      "196, 40\n",
      "248, 40\n",
      "198, 40\n",
      "4340, 40\n",
      "5339, 40\n",
      "6454, 40\n",
      "4051, 40\n",
      "3982, 40\n",
      "6078, 40\n",
      "3857, 40\n",
      "1098, 40\n",
      "5867, 40\n",
      "2159, 40\n",
      "83, 40\n",
      "730, 40\n",
      "1235, 40\n",
      "8629, 40\n",
      "696, 40\n",
      "289, 40\n",
      "1116, 40\n",
      "5808, 40\n",
      "8063, 40\n",
      "8465, 40\n",
      "6272, 40\n",
      "6064, 40\n",
      "412, 40\n",
      "3607, 40\n",
      "1594, 40\n",
      "7278, 40\n",
      "625, 40\n",
      "2836, 40\n",
      "7859, 40\n",
      "3807, 40\n",
      "1355, 40\n",
      "332, 40\n",
      "8580, 40\n",
      "911, 40\n",
      "6880, 40\n",
      "8051, 40\n",
      "8088, 40\n",
      "3436, 40\n",
      "887, 40\n",
      "3879, 40\n",
      "39, 40\n",
      "3235, 40\n",
      "211, 40\n",
      "5652, 40\n",
      "2136, 40\n",
      "4406, 40\n",
      "27, 40\n",
      "1737, 40\n",
      "7059, 40\n",
      "125, 40\n",
      "3486, 40\n",
      "2911, 40\n",
      "7190, 40\n",
      "6437, 40\n",
      "2092, 40\n",
      "7517, 40\n",
      "6925, 40\n",
      "8747, 40\n",
      "7402, 40\n",
      "8609, 40\n",
      "2691, 40\n",
      "2952, 40\n",
      "1040, 40\n",
      "1081, 40\n",
      "2289, 40\n",
      "298, 40\n",
      "4397, 40\n",
      "7264, 40\n",
      "1578, 40\n",
      "60, 40\n",
      "229, 40\n",
      "3699, 40\n",
      "8419, 40\n",
      "4137, 40\n",
      "405, 40\n",
      "2436, 40\n",
      "1898, 40\n",
      "7511, 40\n",
      "4195, 40\n",
      "669, 40\n",
      "5561, 40\n",
      "1447, 40\n",
      "441, 40\n",
      "8098, 40\n",
      "4640, 40\n"
     ]
    }
   ],
   "source": [
    "for s in os.listdir('/cas/DeepLearn/elperu/tmp/speech_datasets/LibriSpeech/train_features/'):\n",
    "    c = os.listdir(os.path.join('/cas/DeepLearn/elperu/tmp/speech_datasets/LibriSpeech/train_features/', s))\n",
    "    print(f'{s}, {len(c)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:speaker]",
   "language": "python",
   "name": "conda-env-speaker-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
